{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for adding noise and segmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "def add_noise_to_audio(audio, noise_level=0.02):\n",
    "\n",
    "    # Convert audio to numpy array (pydub uses raw audio)\n",
    "    samples = np.array(audio.get_array_of_samples())\n",
    "    \n",
    "    # Generate random noise\n",
    "    noise = np.random.normal(0, noise_level * np.max(samples), samples.shape).astype(samples.dtype)\n",
    "    \n",
    "    # Add noise to the audio signal\n",
    "    noisy_samples = samples + noise\n",
    "    noisy_samples = np.clip(noisy_samples, -32768, 32767)  # Ensure values are within int16 range\n",
    "    \n",
    "    # Convert numpy array back to AudioSegment\n",
    "    noisy_audio = AudioSegment(\n",
    "        noisy_samples.tobytes(),\n",
    "        frame_rate=audio.frame_rate,\n",
    "        sample_width=audio.sample_width,\n",
    "        channels=audio.channels\n",
    "    )\n",
    "    \n",
    "    return noisy_audio\n",
    "\n",
    "def split_or_pad_audio(file_path, output_dir, segment_duration=5000):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(file_path, format=\"flac\")\n",
    "    audio_length = len(audio)\n",
    "    \n",
    "    # Calculate the number of 5-second segments\n",
    "    num_segments = math.ceil(audio_length / segment_duration)\n",
    "    \n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        start = i * segment_duration\n",
    "        end = start + segment_duration\n",
    "        segment = audio[start:end]\n",
    "        \n",
    "        # If segment is less than 5 seconds, pad with silence\n",
    "        if len(segment) < segment_duration:\n",
    "            segment = segment + AudioSegment.silent(duration=(segment_duration - len(segment)))\n",
    "        \n",
    "        # Define the output file path\n",
    "        segment_filename = f\"{os.path.splitext(os.path.basename(file_path))[0]}_seg_{i}.flac\"\n",
    "        segment_path = os.path.join(output_dir, segment_filename)\n",
    "    \n",
    "\n",
    "        noisy_seg = add_noise_to_audio(segment)\n",
    "        noisy_path = segment_path.replace(\"clean\",\"noisy\")\n",
    "        noisy_dir = os.path.dirname(noisy_path)\n",
    "        os.makedirs(noisy_dir, exist_ok=True)\n",
    "        noisy_seg.export(noisy_path, \"flac\")\n",
    "        \n",
    "        # Export the segment\n",
    "        segment.export(segment_path, format=\"flac\")\n",
    "        segments.append(segment_path)\n",
    "\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Audios in 5 seconds and adding noise\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset = []\n",
    "count = 0\n",
    "max_files = 5\n",
    "\n",
    "for root, dirs1, files in os.walk(\"LibriSpeech/dev-clean\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".flac\"):\n",
    "            audio_path = os.path.join(root, file)\n",
    "            output_dir = os.path.dirname(audio_path.replace(\"dev-clean\", \"segments/clean\"))\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            segment_list = split_or_pad_audio(audio_path,output_dir,5000)\n",
    "            for segment in segment_list:\n",
    "                clean_path = segment\n",
    "                noisy_path = clean_path.replace(\"clean\", \"noisy\")\n",
    "                dataset.append((noisy_path, segment))\n",
    "            count += 1\n",
    "            \n",
    "            if count >= max_files:\n",
    "                break\n",
    "    if count >= max_files:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame(dataset,columns=[\"noisy_path\", \"clean_path\"])\n",
    "df.to_csv(\"audio_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, metadata_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metadata_file (str): Path to the file with audio file paths and labels.\n",
    "            transform (callable, optional): Optional transform to apply on a sample.\n",
    "        \"\"\"\n",
    "        self.metadata = pd.read_csv(metadata_file, names=['noisy_path', 'clean_path'], skiprows=1)  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve file paths for noisy and clean audio\n",
    "        noisy_path = self.metadata.iloc[idx]['noisy_path']\n",
    "        clean_path = self.metadata.iloc[idx]['clean_path']\n",
    "        \n",
    "        # Load audio and calculate spectrogram from clean and noisy audio\n",
    "        y_noisy, sr = librosa.load(noisy_path, sr=None)\n",
    "        if not isinstance(y_noisy, np.ndarray):\n",
    "           y_noisy = np.array(y_noisy)\n",
    "        S_noisy = librosa.stft(y_noisy, n_fft=2048, hop_length=256)\n",
    "        S_dB_noisy = librosa.amplitude_to_db(np.abs(S_noisy), ref=np.max)\n",
    "\n",
    "        y_clean, sr = librosa.load(clean_path, sr=None)\n",
    "        if not isinstance(y_clean, np.ndarray):\n",
    "            y_clean = np.array(y_clean)\n",
    "        S_clean = librosa.stft(y_clean, n_fft=2048, hop_length=256)\n",
    "        S_dB_clean = librosa.amplitude_to_db(np.abs(S_clean), ref=np.max)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        S_dB_noisy = torch.tensor(S_dB_noisy, dtype=torch.float32)\n",
    "        S_dB_clean = torch.tensor(S_dB_clean, dtype=torch.float32)\n",
    "        \n",
    "        return S_dB_noisy, S_dB_clean\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabajo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
